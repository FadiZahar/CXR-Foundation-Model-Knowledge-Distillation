Metric,chexpert--cxrfmkd_kdinit_mse&cosinesimlearned_multirun-seed41.luna.70002.log,chexpert--cxrfmkd_kdinit_mse&cosinesimlearned_multirun-seed42.luna.70003.log,chexpert--cxrfmkd_kdinit_mse&cosinesimlearned_multirun-seed43.loki.70023.log,chexpert--cxrfmkd_kdinit_mse&cosinesimlearned_multirun-seed44.loki.70024.log,chexpert--cxrfmkd_kdinit_mse&cosinesimlearned_multirun-seed45.loki.70025.log,mimic--cxrfmkd_kdinit_mse&cosinesimlearned_multirun-seed41.loki.71045.log,mimic--cxrfmkd_kdinit_mse&cosinesimlearned_multirun-seed42.loki.71046.log,mimic--cxrfmkd_kdinit_mse&cosinesimlearned_multirun-seed43.loki.71047.log,mimic--cxrfmkd_kdinit_mse&cosinesimlearned_multirun-seed44.loki.71048.log,mimic--cxrfmkd_kdinit_mse&cosinesimlearned_multirun-seed45.loki.71049.log
epoch,40,40,40,40,40,40,40,40,40,40
learning_rate,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
log_var_cosinesim_epoch,-4.66629,-4.66607,-4.59827,-4.66543,-4.66834,-4.68238,-4.68053,-4.68158,-4.67845,-4.67047
log_var_cosinesim_step,-4.66649,-4.66619,-4.59836,-4.66545,-4.66845,-4.68236,-4.68064,-4.68154,-4.67862,-4.6706
log_var_mse_epoch,-2.60173,-2.60238,-2.52639,-2.60044,-2.60386,-2.69262,-2.69034,-2.69262,-2.68924,-2.67895
log_var_mse_step,-2.60187,-2.60251,-2.52657,-2.60055,-2.604,-2.69267,-2.69049,-2.69268,-2.6895,-2.67916
test_loss_epoch,-4.83668,-4.85467,-4.82068,-4.8799,-4.85049,-5.09797,-5.09107,-5.096,-5.09488,-5.07484
test_loss_step,-4.81039,-4.83807,-4.80682,-4.82316,-4.80905,-5.07306,-5.22553,-5.00885,-5.22483,-5.05612
train_loss_epoch,-5.27299,-5.27056,-5.13096,-5.26826,-5.27445,-5.3752,-5.37332,-5.37472,-5.3724,-5.35224
train_loss_step,-5.19178,-5.25801,-5.02944,-5.23903,-5.16752,-5.41241,-5.27075,-5.31403,-5.26007,-5.32534
trainer/global_step,23840,23840,23840,23840,23840,34480,34480,34480,34480,34480
val_final_loss_epoch,-4.85798,-4.84175,-4.8124,-4.84284,-4.85825,-5.08665,-5.09675,-5.08743,-5.08249,-5.08324
val_final_loss_step,-4.89609,-4.73531,-4.68719,-4.95059,-4.90353,-5.12666,-5.02858,-5.14854,-5.10384,-5.1091
val_loss_epoch,-4.85781,-4.84153,-4.81228,-4.84177,-4.85671,-5.08665,-5.09658,-5.08743,-5.08249,-5.08311
val_loss_step,-4.88981,-4.73184,-4.6866,-4.94659,-4.89643,-5.12666,-5.02663,-5.14854,-5.10384,-5.10451
